{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1b44211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minfy.DESKTOP-ISK45CC.000\\anaconda3\\envs\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import kagglehub\n",
    "import mlflow\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import PowerTransformer, RobustScaler, StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "    \n",
    "from evidently import Dataset\n",
    "from evidently import DataDefinition\n",
    "from evidently import Report\n",
    "from evidently.presets import DataDriftPreset, DataSummaryPreset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29dcae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save dir\n",
    "import os\n",
    "SAVEDIR = os.getenv('ARTIFACT_DIR', '.') + '/saved_models'\n",
    "os.makedirs(SAVEDIR, exist_ok=True)\n",
    "\n",
    "def load_data():\n",
    "    path = kagglehub.dataset_download(\"itsmesunil/bank-loan-modelling\")\n",
    "    df = pd.read_excel(\n",
    "        os.path.join(path, \"Bank_Personal_Loan_Modelling.csv\"),\n",
    "        sheet_name='Data'\n",
    "    )\n",
    "    # DROP via keyword axis=\n",
    "    return df.drop(['ID', 'ZIP Code'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12f970bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_data(df):\n",
    "    X = df.drop('Personal Loan', axis=1)\n",
    "    y = df['Personal Loan']\n",
    "    X0, X_test, y0, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=42\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X0, y0, test_size=0.2, stratify=y0, random_state=42\n",
    "    )\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98a6e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fit(X_train, X_val, X_test):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from scipy.stats import skew\n",
    "\n",
    "    rb = ['CCAvg','Mortgage']\n",
    "    st = ['Income','Experience','Age']\n",
    "\n",
    "    # === 1. Skewness Check ===\n",
    "    ''' print(\"\\nðŸ“ˆ Skewness Before Transformation:\")\n",
    "    skew_vals = X_train[rb + st].apply(skew)\n",
    "    print(skew_vals)\n",
    "\n",
    "    # === 2. Histograms Before Transformation ===\n",
    "    X_train[rb + st].hist(bins=30, figsize=(12, 8), color='skyblue', edgecolor='black')\n",
    "    plt.suptitle(\"Histograms Before Transformation\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # === 3. Boxplots Before Transformation ===\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    for i, col in enumerate(rb + st, 1):\n",
    "        plt.subplot(2, 3, i)\n",
    "        sns.boxplot(y=X_train[col], color='lightcoral')\n",
    "        plt.title(f\"Boxplot: {col}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()'''\n",
    "\n",
    "    # === 4. Preprocessing Steps ===\n",
    "    pt = PowerTransformer('yeo-johnson')\n",
    "    rs = RobustScaler()\n",
    "    ss = StandardScaler()\n",
    "\n",
    "    X_train[rb] = rs.fit_transform(pt.fit_transform(X_train[rb]))\n",
    "    X_train[st] = ss.fit_transform(X_train[st])\n",
    "\n",
    "    for X in (X_val, X_test):\n",
    "        X[rb] = rs.transform(pt.transform(X[rb]))\n",
    "        X[st] = ss.transform(X[st])\n",
    "\n",
    "    joblib.dump(pt, os.path.join(SAVEDIR, 'pt.pkl'))\n",
    "    joblib.dump(rs, os.path.join(SAVEDIR, 'rs.pkl'))\n",
    "    joblib.dump(ss, os.path.join(SAVEDIR, 'ss.pkl'))\n",
    "\n",
    "    return X_train, X_val, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adc0f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_eda(df):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    sns.set(font_scale=1.1)\n",
    "\n",
    "    # === 1. Target Variable Distribution ===\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(data=df, x='Personal Loan', palette='Set2')\n",
    "    plt.title(\"Target Variable: Personal Loan\")\n",
    "    plt.xlabel(\"Personal Loan (0 = No, 1 = Yes)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "    # === 2. Univariate Analysis ===\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    sns.histplot(df['Age'], bins=20, kde=True, ax=axes[0], color='skyblue')\n",
    "    axes[0].set_title(\"Age Distribution\")\n",
    "\n",
    "    sns.histplot(df['Experience'], bins=20, kde=True, ax=axes[1], color='lightgreen')\n",
    "    axes[1].set_title(\"Experience Distribution\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(df['Income'], bins=20, kde=True, color='salmon')\n",
    "    plt.title(\"Income Distribution\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(df['CCAvg'], bins=20, kde=True, color='plum')\n",
    "    plt.title(\"Average Credit Card Spending\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(df['Mortgage'], bins=20, kde=True, color='gold')\n",
    "    plt.title(\"Mortgage Distribution\")\n",
    "    plt.show()\n",
    "\n",
    "    # === 3. Categorical Features vs Target ===\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    sns.countplot(data=df, x='Education', hue='Personal Loan', palette='pastel')\n",
    "    plt.title(\"Loan Approval by Education Level\")\n",
    "    plt.xlabel(\"Education (1:UG, 2:Graduate, 3:Advanced)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend(title='Loan Approved')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    sns.countplot(data=df, x='Family', hue='Personal Loan', palette='coolwarm')\n",
    "    plt.title(\"Loan Approval by Family Size\")\n",
    "    plt.xlabel(\"Family Members\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend(title='Loan Approved')\n",
    "    plt.show()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    sns.countplot(data=df, x='Online', hue='Personal Loan', ax=axes[0], palette='viridis')\n",
    "    axes[0].set_title(\"Loan by Online Banking\")\n",
    "\n",
    "    sns.countplot(data=df, x='CreditCard', hue='Personal Loan', ax=axes[1], palette='magma')\n",
    "    axes[1].set_title(\"Loan by Credit Card Ownership\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # === 4. Bivariate Numerical Analysis ===\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    sns.boxplot(data=df, x='Personal Loan', y='Income', palette='Set3')\n",
    "    plt.title(\"Income vs Loan Status\")\n",
    "    plt.xlabel(\"Personal Loan\")\n",
    "    plt.ylabel(\"Income\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    sns.scatterplot(data=df, x='CCAvg', y='Mortgage', hue='Personal Loan', palette='coolwarm', alpha=0.7)\n",
    "    plt.title(\"CCAvg vs Mortgage by Loan Status\")\n",
    "    plt.xlabel(\"Avg Credit Card Spend\")\n",
    "    plt.ylabel(\"Mortgage\")\n",
    "    plt.show()\n",
    "\n",
    "    # === 5. Pairplot ===\n",
    "    selected = ['Age', 'Experience', 'Income', 'CCAvg', 'Mortgage', 'Personal Loan']\n",
    "    sns.pairplot(df[selected], hue='Personal Loan', palette='husl', diag_kind='kde')\n",
    "    plt.suptitle(\"Pairplot of Important Features\", y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "    # === 6. Correlation Heatmap ===\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    corr = df.corr()\n",
    "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True)\n",
    "    plt.title(\"Correlation Heatmap\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29152002",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature_select_fit(X_train, y_train, X_val, X_test):\n",
    "    selector = RFE(LogisticRegression(max_iter=1000), n_features_to_select=8)\n",
    "    Xtr = selector.fit_transform(X_train, y_train)\n",
    "    Xv  = selector.transform(X_val)\n",
    "    Xt  = selector.transform(X_test)\n",
    "    joblib.dump(selector, os.path.join(SAVEDIR, 'selector.pkl'))\n",
    "    return Xtr, Xv, Xt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7206763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def balance(X, y):\n",
    "    sm = SMOTE(random_state=42)\n",
    "    return sm.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43975a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from evidently import Report\n",
    "from evidently.presets import DataDriftPreset, DataSummaryPreset\n",
    "import mlflow\n",
    "\n",
    "def log_evidently_report(reference_data, current_data, dataset_name=\"train_vs_test\"):\n",
    "    report = Report(metrics=[\n",
    "        DataDriftPreset(),\n",
    "        DataSummaryPreset()\n",
    "    ])\n",
    "   \n",
    "    result = report.run(reference_data=reference_data, current_data=current_data)\n",
    " \n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    html_path = f\"evidently_{dataset_name}_{timestamp}.html\"\n",
    "   \n",
    "    result.save_html(html_path)  # âœ… Supported in evidently >= 0.4.0\n",
    "   \n",
    "    mlflow.log_artifact(html_path, artifact_path=\"evidently\")\n",
    "    print(f\"ðŸ“„ Evidently report logged: {html_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afa342c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import yaml\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import Metric\n",
    "from mlflow.utils.yaml_utils import YamlSafeDumper\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# â”€â”€â”€ 1) Patch MLflowâ€™s YAML dumper so any object is stringified â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Catch Metric explicitly\n",
    "YamlSafeDumper.add_multi_representer(\n",
    "    Metric,\n",
    "    lambda dumper, metric: dumper.represent_scalar(\n",
    "        'tag:yaml.org,2002:str',\n",
    "        f\"{metric.key}={metric.value:.6f}@{metric.timestamp}\"\n",
    "    )\n",
    ")\n",
    "# Catch _everything else_ so nothing breaks\n",
    "YamlSafeDumper.add_multi_representer(\n",
    "    object,\n",
    "    lambda dumper, obj: dumper.represent_scalar(\n",
    "        'tag:yaml.org,2002:str',\n",
    "        str(obj)\n",
    "    )\n",
    ")\n",
    "\n",
    "# â”€â”€â”€ 2) Setup localâ€save directory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SAVEDIR = \"saved_models\"\n",
    "os.makedirs(SAVEDIR, exist_ok=True)\n",
    "\n",
    "def tune_and_save(X, y, X_val, y_val):\n",
    "    mlflow.set_experiment(\"Bank Loan Classification\")\n",
    "    client = MlflowClient()\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    best_model_name = None\n",
    "    best_model_path = None\n",
    "\n",
    "    grids = {\n",
    "        'LogisticRegression': {\n",
    "            'model': LogisticRegression(max_iter=1000),\n",
    "            'params': {'C': [0.01, 0.1, 1, 10],\n",
    "                       'penalty': ['l1', 'l2'],\n",
    "                       'solver': ['liblinear']}\n",
    "        },\n",
    "        'DecisionTree': {\n",
    "            'model': DecisionTreeClassifier(),\n",
    "            'params': {'max_depth': [3, 5, 7, None],\n",
    "                       'min_samples_split': [2, 5, 10],\n",
    "                       'min_samples_leaf': [1, 2, 4]}\n",
    "        },\n",
    "        'RandomForest': {\n",
    "            'model': RandomForestClassifier(random_state=42),\n",
    "            'params': {'n_estimators': [50, 100],\n",
    "                       'max_depth': [5, 10, None]}\n",
    "        },\n",
    "        'GradientBoosting': {\n",
    "            'model': GradientBoostingClassifier(random_state=42),\n",
    "            'params': {'n_estimators': [50, 100],\n",
    "                       'learning_rate': [0.01, 0.1]}\n",
    "        },\n",
    "        'KNN': {\n",
    "            'model': KNeighborsClassifier(),\n",
    "            'params': {'n_neighbors': [3, 5, 7]}\n",
    "        },\n",
    "        'SVM': {\n",
    "            'model': SVC(probability=True, random_state=42),\n",
    "            'params': {'C': [0.1, 1, 10],\n",
    "                       'kernel': ['linear', 'rbf']}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for name, cfg in grids.items():\n",
    "        with mlflow.start_run(run_name=name, nested=True) as run:\n",
    "            # Not using broad autolog to avoid unexpected objects\n",
    "            # mlflow.sklearn.autolog(log_models=True, log_input_examples=False)\n",
    "\n",
    "            gs = GridSearchCV(cfg['model'], cfg['params'], scoring='f1',\n",
    "                              cv=5, n_jobs=-1)\n",
    "            gs.fit(X, y)\n",
    "            best_model = gs.best_estimator_\n",
    "\n",
    "            preds = best_model.predict(X_val)\n",
    "            acc = accuracy_score(y_val, preds)\n",
    "            prec = precision_score(y_val, preds)\n",
    "            rec = recall_score(y_val, preds)\n",
    "            f1 = f1_score(y_val, preds)\n",
    "\n",
    "            # Only primitive metric logging\n",
    "            mlflow.log_metrics({\n",
    "                \"val_accuracy\": acc,\n",
    "                \"val_precision\": prec,\n",
    "                \"val_recall\": rec,\n",
    "                \"val_f1\": f1\n",
    "            })\n",
    "\n",
    "            print(f\"{name} tuned â†’ {gs.best_params_}\")\n",
    "            print(f\"â†’ Accuracy: {acc:.3f}, Precision: {prec:.3f}, \"\n",
    "                  f\"Recall: {rec:.3f}, F1: {f1:.3f}\")\n",
    "\n",
    "            # Save locally and log artifact\n",
    "            local_path = os.path.join(SAVEDIR, f\"{name}_model.pkl\")\n",
    "            joblib.dump(best_model, local_path)\n",
    "            mlflow.sklearn.log_model(best_model, artifact_path=\"model\")\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_model_name = name\n",
    "                best_model_path = f\"runs:/{run.info.run_id}/model\"\n",
    "\n",
    "    # Register & promote to Production\n",
    "    if best_model_name and best_model_path:\n",
    "        print(f\"\\nðŸ† Registering best model: {best_model_name} (F1={best_f1:.3f})\")\n",
    "        mv = mlflow.register_model(\n",
    "            model_uri=best_model_path,\n",
    "            name=\"BankLoanBestModel\"\n",
    "        )\n",
    "        print(f\"âœ… Registered: {mv.name}, version {mv.version}\")\n",
    "\n",
    "        # Wait for registry metadata to be ready\n",
    "        for _ in range(15):\n",
    "            info = client.get_model_version(name=mv.name, version=mv.version)\n",
    "            if info.status == \"READY\":\n",
    "                break\n",
    "            time.sleep(1)\n",
    "\n",
    "        client.transition_model_version_stage(\n",
    "            name=mv.name,\n",
    "            version=mv.version,\n",
    "            stage=\"Production\",\n",
    "            archive_existing_versions=True\n",
    "        )\n",
    "        print(f\"ðŸš€ {mv.name} v{mv.version} â†’ Production\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b159f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    mlflow.set_experiment(\"Bank Loan Classification\")\n",
    "\n",
    "    with mlflow.start_run(run_name=\"Preprocessing and Tuning\"):\n",
    "        df = load_data()\n",
    "        Xtr, Xv, Xt, ytr, yv, yt = split_data(df)\n",
    "\n",
    "        # Save unprocessed versions for Evidently\n",
    "        df_train = Xtr.copy()\n",
    "        df_test = Xt.copy()\n",
    "\n",
    "        # Simulate new batch\n",
    "        # Replace this with your actual CSV path\n",
    "        csv_path = \"New_Customer_Bank_Personal_Loan.csv\"\n",
    "\n",
    "        # Load new data from a CSV file\n",
    "        df_new = pd.read_csv(csv_path)\n",
    "\n",
    "        # Ensure target column is dropped (since this is new/unlabeled data)\n",
    "        if \"Personal Loan\" in df_new.columns:\n",
    "            df_new = df_new.drop(columns=[\"Personal Loan\"])\n",
    "\n",
    "        df_new = df.sample(n=200, replace=True, random_state=42).drop(columns=[\"Personal Loan\"])\n",
    "\n",
    "        # Preprocess\n",
    "        Xtr, Xv, Xt = preprocess_fit(Xtr, Xv, Xt)\n",
    "        Xtf, Xvf, Xsf = feature_select_fit(Xtr, ytr, Xv, Xt)\n",
    "\n",
    "        # Log preprocessing artifacts\n",
    "        for file in ['pt.pkl', 'rs.pkl', 'ss.pkl', 'selector.pkl']:\n",
    "            mlflow.log_artifact(os.path.join(SAVEDIR, file))\n",
    "\n",
    "        Xb, yb = balance(Xtf, ytr)\n",
    "        tune_and_save(Xb, yb, Xvf, yv)\n",
    "\n",
    "        # Log Evidently reports\n",
    "        log_evidently_report(df_train, df_test, dataset_name=\"train_vs_test\")\n",
    "        log_evidently_report(df_train, df_new, dataset_name=\"train_vs_new_batch\")\n",
    "        log_evidently_report(df_test, df_new, dataset_name=\"test_vs_new_batch\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0266f74d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'New_Customer_Bank_Personal_Loan.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m==\u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     14\u001b[39m csv_path = \u001b[33m\"\u001b[39m\u001b[33mNew_Customer_Bank_Personal_Loan.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Load new data from a CSV file\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m df_new = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Ensure target column is dropped (since this is new/unlabeled data)\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mPersonal Loan\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df_new.columns:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Minfy.DESKTOP-ISK45CC.000\\anaconda3\\envs\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Minfy.DESKTOP-ISK45CC.000\\anaconda3\\envs\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Minfy.DESKTOP-ISK45CC.000\\anaconda3\\envs\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Minfy.DESKTOP-ISK45CC.000\\anaconda3\\envs\\env\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Minfy.DESKTOP-ISK45CC.000\\anaconda3\\envs\\env\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'New_Customer_Bank_Personal_Loan.csv'"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
