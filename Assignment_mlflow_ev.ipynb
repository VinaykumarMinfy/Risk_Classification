{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b44211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Minfy.DESKTOP-ISK45CC.000\\anaconda3\\envs\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import kagglehub\n",
    "import mlflow\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import PowerTransformer, RobustScaler, StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "    \n",
    "from evidently import Dataset\n",
    "from evidently import DataDefinition\n",
    "from evidently import Report\n",
    "from evidently.presets import DataDriftPreset, DataSummaryPreset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29dcae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save dir\n",
    "import os\n",
    "SAVEDIR = os.getenv('ARTIFACT_DIR', '.') + '/saved_models'\n",
    "os.makedirs(SAVEDIR, exist_ok=True)\n",
    "\n",
    "def load_data():\n",
    "    path = kagglehub.dataset_download(\"itsmesunil/bank-loan-modelling\")\n",
    "    df = pd.read_excel(\n",
    "        os.path.join(path, \"Bank_Personal_Loan_Modelling.xlsx\"),\n",
    "        sheet_name='Data'\n",
    "    )\n",
    "    # DROP via keyword axis=\n",
    "    return df.drop(['ID', 'ZIP Code'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f970bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_data(df):\n",
    "    X = df.drop('Personal Loan', axis=1)\n",
    "    y = df['Personal Loan']\n",
    "    X0, X_test, y0, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, stratify=y, random_state=42\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X0, y0, test_size=0.2, stratify=y0, random_state=42\n",
    "    )\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a6e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fit(X_train, X_val, X_test):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from scipy.stats import skew\n",
    "\n",
    "    rb = ['CCAvg','Mortgage']\n",
    "    st = ['Income','Experience','Age']\n",
    "\n",
    "    # === 1. Skewness Check ===\n",
    "    ''' print(\"\\n📈 Skewness Before Transformation:\")\n",
    "    skew_vals = X_train[rb + st].apply(skew)\n",
    "    print(skew_vals)\n",
    "\n",
    "    # === 2. Histograms Before Transformation ===\n",
    "    X_train[rb + st].hist(bins=30, figsize=(12, 8), color='skyblue', edgecolor='black')\n",
    "    plt.suptitle(\"Histograms Before Transformation\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # === 3. Boxplots Before Transformation ===\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    for i, col in enumerate(rb + st, 1):\n",
    "        plt.subplot(2, 3, i)\n",
    "        sns.boxplot(y=X_train[col], color='lightcoral')\n",
    "        plt.title(f\"Boxplot: {col}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()'''\n",
    "\n",
    "    # === 4. Preprocessing Steps ===\n",
    "    pt = PowerTransformer('yeo-johnson')\n",
    "    rs = RobustScaler()\n",
    "    ss = StandardScaler()\n",
    "\n",
    "    X_train[rb] = rs.fit_transform(pt.fit_transform(X_train[rb]))\n",
    "    X_train[st] = ss.fit_transform(X_train[st])\n",
    "\n",
    "    for X in (X_val, X_test):\n",
    "        X[rb] = rs.transform(pt.transform(X[rb]))\n",
    "        X[st] = ss.transform(X[st])\n",
    "\n",
    "    joblib.dump(pt, os.path.join(SAVEDIR, 'pt.pkl'))\n",
    "    joblib.dump(rs, os.path.join(SAVEDIR, 'rs.pkl'))\n",
    "    joblib.dump(ss, os.path.join(SAVEDIR, 'ss.pkl'))\n",
    "\n",
    "    return X_train, X_val, X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc0f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_eda(df):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    sns.set(font_scale=1.1)\n",
    "\n",
    "    # === 1. Target Variable Distribution ===\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(data=df, x='Personal Loan', palette='Set2')\n",
    "    plt.title(\"Target Variable: Personal Loan\")\n",
    "    plt.xlabel(\"Personal Loan (0 = No, 1 = Yes)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "    # === 2. Univariate Analysis ===\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    sns.histplot(df['Age'], bins=20, kde=True, ax=axes[0], color='skyblue')\n",
    "    axes[0].set_title(\"Age Distribution\")\n",
    "\n",
    "    sns.histplot(df['Experience'], bins=20, kde=True, ax=axes[1], color='lightgreen')\n",
    "    axes[1].set_title(\"Experience Distribution\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(df['Income'], bins=20, kde=True, color='salmon')\n",
    "    plt.title(\"Income Distribution\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(df['CCAvg'], bins=20, kde=True, color='plum')\n",
    "    plt.title(\"Average Credit Card Spending\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(df['Mortgage'], bins=20, kde=True, color='gold')\n",
    "    plt.title(\"Mortgage Distribution\")\n",
    "    plt.show()\n",
    "\n",
    "    # === 3. Categorical Features vs Target ===\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    sns.countplot(data=df, x='Education', hue='Personal Loan', palette='pastel')\n",
    "    plt.title(\"Loan Approval by Education Level\")\n",
    "    plt.xlabel(\"Education (1:UG, 2:Graduate, 3:Advanced)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend(title='Loan Approved')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    sns.countplot(data=df, x='Family', hue='Personal Loan', palette='coolwarm')\n",
    "    plt.title(\"Loan Approval by Family Size\")\n",
    "    plt.xlabel(\"Family Members\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend(title='Loan Approved')\n",
    "    plt.show()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    sns.countplot(data=df, x='Online', hue='Personal Loan', ax=axes[0], palette='viridis')\n",
    "    axes[0].set_title(\"Loan by Online Banking\")\n",
    "\n",
    "    sns.countplot(data=df, x='CreditCard', hue='Personal Loan', ax=axes[1], palette='magma')\n",
    "    axes[1].set_title(\"Loan by Credit Card Ownership\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # === 4. Bivariate Numerical Analysis ===\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    sns.boxplot(data=df, x='Personal Loan', y='Income', palette='Set3')\n",
    "    plt.title(\"Income vs Loan Status\")\n",
    "    plt.xlabel(\"Personal Loan\")\n",
    "    plt.ylabel(\"Income\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    sns.scatterplot(data=df, x='CCAvg', y='Mortgage', hue='Personal Loan', palette='coolwarm', alpha=0.7)\n",
    "    plt.title(\"CCAvg vs Mortgage by Loan Status\")\n",
    "    plt.xlabel(\"Avg Credit Card Spend\")\n",
    "    plt.ylabel(\"Mortgage\")\n",
    "    plt.show()\n",
    "\n",
    "    # === 5. Pairplot ===\n",
    "    selected = ['Age', 'Experience', 'Income', 'CCAvg', 'Mortgage', 'Personal Loan']\n",
    "    sns.pairplot(df[selected], hue='Personal Loan', palette='husl', diag_kind='kde')\n",
    "    plt.suptitle(\"Pairplot of Important Features\", y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "    # === 6. Correlation Heatmap ===\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    corr = df.corr()\n",
    "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True)\n",
    "    plt.title(\"Correlation Heatmap\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29152002",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature_select_fit(X_train, y_train, X_val, X_test):\n",
    "    selector = RFE(LogisticRegression(max_iter=1000), n_features_to_select=8)\n",
    "    Xtr = selector.fit_transform(X_train, y_train)\n",
    "    Xv  = selector.transform(X_val)\n",
    "    Xt  = selector.transform(X_test)\n",
    "    joblib.dump(selector, os.path.join(SAVEDIR, 'selector.pkl'))\n",
    "    return Xtr, Xv, Xt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7206763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def balance(X, y):\n",
    "    sm = SMOTE(random_state=42)\n",
    "    return sm.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43975a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import mlflow\n",
    "from evidently import Report\n",
    "from evidently.presets import DataDriftPreset, DataSummaryPreset\n",
    "\n",
    "def log_evidently_report(reference_data, current_data, dataset_name=\"train_vs_test\"):\n",
    "    \"\"\"\n",
    "    Generates an Evidently data drift + summary report on the common columns between reference and current,\n",
    "    saves HTML and JSON, logs both as MLflow artifacts, and extracts key drift metrics including per-feature drift.\n",
    "\n",
    "    Args:\n",
    "        reference_data: DataFrame for reference (e.g. training) dataset.\n",
    "        current_data: DataFrame for current (e.g. test or new batch) dataset.\n",
    "        dataset_name: Identifier used for naming artifacts.\n",
    "    \"\"\"\n",
    "    # 0️⃣ Align columns: use only the intersection to avoid partial-column errors\n",
    "    common_cols = set(reference_data.columns).intersection(current_data.columns)\n",
    "    if not common_cols:\n",
    "        print(f\"⚠️ No common columns between reference and {dataset_name}; skipping Evidently report.\")\n",
    "        return\n",
    "    ref = reference_data[sorted(common_cols)]\n",
    "    cur = current_data[sorted(common_cols)]\n",
    "\n",
    "    # 1️⃣ Run the Evidently report (drift + summary)\n",
    "    report = Report(metrics=[DataDriftPreset(), DataSummaryPreset()])\n",
    "    result = report.run(reference_data=ref, current_data=cur)\n",
    "\n",
    "    # 2️⃣ Ensure local save directory exists\n",
    "    save_dir = Path.cwd() / \"evidently_reports\"\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 3️⃣ Save HTML and JSON\n",
    "    ts = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    html_path = save_dir / f\"evidently_{dataset_name}_{ts}.html\"\n",
    "    json_path = save_dir / f\"evidently_{dataset_name}_{ts}.json\"\n",
    "    result.save_html(str(html_path))\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as fp:\n",
    "        fp.write(result.json())\n",
    "\n",
    "    # 4️⃣ Log artifacts to MLflow\n",
    "    mlflow.log_artifact(str(html_path), artifact_path=\"evidently\")\n",
    "    mlflow.log_artifact(str(json_path), artifact_path=\"evidently\")\n",
    "    print(f\"📄 Logged HTML: {html_path.name}\")\n",
    "    print(f\"🗄️  Logged JSON: {json_path.name}\")\n",
    "\n",
    "    # 5️⃣ Load JSON and extract metrics list\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as fp:\n",
    "        report_json = json.load(fp)\n",
    "    metrics_list = report_json.get(\"metrics\", [])\n",
    "\n",
    "    # 6️⃣ Overall drifted columns metrics\n",
    "    drift_entry = next((m for m in metrics_list if m.get(\"metric_id\", \"\").startswith(\"DriftedColumnsCount\")), None)\n",
    "    if drift_entry:\n",
    "        count = drift_entry[\"value\"][\"count\"]\n",
    "        share = drift_entry[\"value\"][\"share\"]\n",
    "        mlflow.log_metric(\"drifted_columns_count\", float(count))\n",
    "        mlflow.log_metric(\"drifted_columns_share\", float(share))\n",
    "        print(f\"🔢 drifted_columns_count = {count}\")\n",
    "        print(f\"🔢 drifted_columns_share = {share}\")\n",
    "    else:\n",
    "        print(\"⚠️ No DriftedColumnsCount entry found.\")\n",
    "\n",
    "    # 7️⃣ Row and column counts\n",
    "    rowcount = next((m[\"value\"] for m in metrics_list if m.get(\"metric_id\") == \"RowCount()\"), None)\n",
    "    colcount = next((m[\"value\"] for m in metrics_list if m.get(\"metric_id\") == \"ColumnCount()\"), None)\n",
    "    if rowcount is not None:\n",
    "        mlflow.log_metric(\"dataset_row_count\", float(rowcount))\n",
    "        print(f\"🔢 dataset_row_count = {rowcount}\")\n",
    "    if colcount is not None:\n",
    "        mlflow.log_metric(\"dataset_column_count\", float(colcount))\n",
    "        print(f\"🔢 dataset_column_count = {colcount}\")\n",
    "\n",
    "    # 8️⃣ Per-feature value drift metrics\n",
    "    for m in metrics_list:\n",
    "        mid = m.get(\"metric_id\", \"\")\n",
    "        if mid.startswith(\"ValueDrift(column=\"):\n",
    "            # extract column name\n",
    "            col = mid.split(\"=\")[1].rstrip(\")\")\n",
    "            val = m.get(\"value\")\n",
    "            if isinstance(val, (int, float)):\n",
    "                mlflow.log_metric(f\"drift_{col}\", float(val))\n",
    "                print(f\"🔢 drift_{col} = {val}\")\n",
    "    \n",
    "    print(\"✅ All requested drift & dataset metrics logged to MLflow.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa342c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import yaml\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.entities import Metric\n",
    "from mlflow.utils.yaml_utils import YamlSafeDumper\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ─── 1) Patch MLflow’s YAML dumper so any object is stringified ─────────────\n",
    "# Catch Metric explicitly\n",
    "YamlSafeDumper.add_multi_representer(\n",
    "    Metric,\n",
    "    lambda dumper, metric: dumper.represent_scalar(\n",
    "        'tag:yaml.org,2002:str',\n",
    "        f\"{metric.key}={metric.value:.6f}@{metric.timestamp}\"\n",
    "    )\n",
    ")\n",
    "# Catch _everything else_ so nothing breaks\n",
    "YamlSafeDumper.add_multi_representer(\n",
    "    object,\n",
    "    lambda dumper, obj: dumper.represent_scalar(\n",
    "        'tag:yaml.org,2002:str',\n",
    "        str(obj)\n",
    "    )\n",
    ")\n",
    "\n",
    "# ─── 2) Setup local‐save directory ─────────────────────────────────────────────\n",
    "SAVEDIR = \"saved_models\"\n",
    "os.makedirs(SAVEDIR, exist_ok=True)\n",
    "\n",
    "def tune_and_save(X, y, X_val, y_val):\n",
    "    mlflow.set_experiment(\"Bank Loan Classification\")\n",
    "    client = MlflowClient()\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    best_model_name = None\n",
    "    best_model_path = None\n",
    "\n",
    "    grids = {\n",
    "        'LogisticRegression': {\n",
    "            'model': LogisticRegression(max_iter=1000),\n",
    "            'params': {'C': [0.01, 0.1, 1, 10],\n",
    "                       'penalty': ['l1', 'l2'],\n",
    "                       'solver': ['liblinear']}\n",
    "        },\n",
    "        'DecisionTree': {\n",
    "            'model': DecisionTreeClassifier(),\n",
    "            'params': {'max_depth': [3, 5, 7, None],\n",
    "                       'min_samples_split': [2, 5, 10],\n",
    "                       'min_samples_leaf': [1, 2, 4]}\n",
    "        },\n",
    "        'RandomForest': {\n",
    "            'model': RandomForestClassifier(random_state=42),\n",
    "            'params': {'n_estimators': [50, 100],\n",
    "                       'max_depth': [5, 10, None]}\n",
    "        },\n",
    "        'GradientBoosting': {\n",
    "            'model': GradientBoostingClassifier(random_state=42),\n",
    "            'params': {'n_estimators': [50, 100],\n",
    "                       'learning_rate': [0.01, 0.1]}\n",
    "        },\n",
    "        'KNN': {\n",
    "            'model': KNeighborsClassifier(),\n",
    "            'params': {'n_neighbors': [3, 5, 7]}\n",
    "        },\n",
    "        'SVM': {\n",
    "            'model': SVC(probability=True, random_state=42),\n",
    "            'params': {'C': [0.1, 1, 10],\n",
    "                       'kernel': ['linear', 'rbf']}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for name, cfg in grids.items():\n",
    "        with mlflow.start_run(run_name=name, nested=True) as run:\n",
    "            # Not using broad autolog to avoid unexpected objects\n",
    "            # mlflow.sklearn.autolog(log_models=True, log_input_examples=False)\n",
    "\n",
    "            gs = GridSearchCV(cfg['model'], cfg['params'], scoring='f1',\n",
    "                              cv=5, n_jobs=-1)\n",
    "            gs.fit(X, y)\n",
    "            best_model = gs.best_estimator_\n",
    "\n",
    "            preds = best_model.predict(X_val)\n",
    "            acc = accuracy_score(y_val, preds)\n",
    "            prec = precision_score(y_val, preds)\n",
    "            rec = recall_score(y_val, preds)\n",
    "            f1 = f1_score(y_val, preds)\n",
    "\n",
    "            # Only primitive metric logging\n",
    "            mlflow.log_metrics({\n",
    "                \"val_accuracy\": acc,\n",
    "                \"val_precision\": prec,\n",
    "                \"val_recall\": rec,\n",
    "                \"val_f1\": f1\n",
    "            })\n",
    "\n",
    "            print(f\"{name} tuned → {gs.best_params_}\")\n",
    "            print(f\"→ Accuracy: {acc:.3f}, Precision: {prec:.3f}, \"\n",
    "                  f\"Recall: {rec:.3f}, F1: {f1:.3f}\")\n",
    "\n",
    "            # Save locally and log artifact\n",
    "            local_path = os.path.join(SAVEDIR, f\"{name}_model.pkl\")\n",
    "            joblib.dump(best_model, local_path)\n",
    "            mlflow.sklearn.log_model(best_model, artifact_path=\"model\")\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_model_name = name\n",
    "                best_model_path = f\"runs:/{run.info.run_id}/model\"\n",
    "\n",
    "    # Register & promote to Production\n",
    "    if best_model_name and best_model_path:\n",
    "        print(f\"\\n🏆 Registering best model: {best_model_name} (F1={best_f1:.3f})\")\n",
    "        mv = mlflow.register_model(\n",
    "            model_uri=best_model_path,\n",
    "            name=\"BankLoanBestModel\"\n",
    "        )\n",
    "        print(f\"✅ Registered: {mv.name}, version {mv.version}\")\n",
    "\n",
    "        # Wait for registry metadata to be ready\n",
    "        for _ in range(15):\n",
    "            info = client.get_model_version(name=mv.name, version=mv.version)\n",
    "            if info.status == \"READY\":\n",
    "                break\n",
    "            time.sleep(1)\n",
    "\n",
    "        client.transition_model_version_stage(\n",
    "            name=mv.name,\n",
    "            version=mv.version,\n",
    "            stage=\"Production\",\n",
    "            archive_existing_versions=True\n",
    "        )\n",
    "        print(f\"🚀 {mv.name} v{mv.version} → Production\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b159f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from mlflow.exceptions import MlflowException\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# … your other imports …\n",
    "\n",
    "EXPERIMENT_NAME = \"Bank Loan Classification\"\n",
    "\n",
    "def main():\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # ─── 1️⃣ Ensure the MLflow experiment exists and is active ───\n",
    "    exp = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "    if exp is None:\n",
    "        exp_id = client.create_experiment(EXPERIMENT_NAME)\n",
    "        print(f\"✅ Created new experiment '{EXPERIMENT_NAME}' (ID={exp_id})\")\n",
    "    elif exp.lifecycle_stage == \"deleted\":\n",
    "        client.restore_experiment(exp.experiment_id)\n",
    "        print(f\"🔄 Restored deleted experiment '{EXPERIMENT_NAME}' (ID={exp.experiment_id})\")\n",
    "    else:\n",
    "        print(f\"ℹ️ Using existing experiment '{EXPERIMENT_NAME}' (ID={exp.experiment_id})\")\n",
    "\n",
    "    mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "    # ─── 2️⃣ Start your MLflow run ───\n",
    "    with mlflow.start_run(run_name=\"Preprocessing and Tuning\"):\n",
    "        # Load and split\n",
    "        df = load_data()\n",
    "        Xtr, Xv, Xt, ytr, yv, yt = split_data(df)\n",
    "\n",
    "        # Keep raw for Evidently\n",
    "        df_train = Xtr.copy()\n",
    "        df_test  = Xt.copy()\n",
    "\n",
    "        # Load or simulate new batch\n",
    "        csv_path = \"New_Customer_Bank_Personal_Loan.csv\"\n",
    "        df_new = pd.read_csv(csv_path)\n",
    "        if \"Personal Loan\" in df_new.columns:\n",
    "            df_new = df_new.drop(columns=[\"Personal Loan\"])\n",
    "        # option: sample instead of reloading\n",
    "        # df_new = df.sample(n=200, replace=True, random_state=42).drop(columns=[\"Personal Loan\"])\n",
    "\n",
    "        # Preprocess & feature‑select\n",
    "        Xtr, Xv, Xt = preprocess_fit(Xtr, Xv, Xt)\n",
    "        Xtf, Xvf, Xsf = feature_select_fit(Xtr, ytr, Xv, Xt)\n",
    "\n",
    "        # Log preprocessing artifacts\n",
    "        for fname in ['pt.pkl', 'rs.pkl', 'ss.pkl', 'selector.pkl']:\n",
    "            mlflow.log_artifact(os.path.join(SAVEDIR, fname))\n",
    "\n",
    "        # Balance and train\n",
    "        Xb, yb = balance(Xtf, ytr)\n",
    "        tune_and_save(Xb, yb, Xvf, yv)\n",
    "\n",
    "        # Log Evidently reports\n",
    "        log_evidently_report(df_train, df_test,      dataset_name=\"train_vs_test\")\n",
    "        log_evidently_report(df_train, df_new,        dataset_name=\"train_vs_new_batch\")\n",
    "        log_evidently_report(df_test,  df_new,        dataset_name=\"test_vs_new_batch\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0266f74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ Using existing experiment 'Bank Loan Classification' (ID=141470624783207037)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/03 02:54:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression tuned → {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "→ Accuracy: 0.884, Precision: 0.446, Recall: 0.866, F1: 0.589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/03 02:54:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/07/03 02:54:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree tuned → {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "→ Accuracy: 0.967, Precision: 0.867, Recall: 0.776, F1: 0.819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/03 02:54:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/07/03 02:55:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest tuned → {'max_depth': None, 'n_estimators': 100}\n",
      "→ Accuracy: 0.983, Precision: 0.982, Recall: 0.836, F1: 0.903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/03 02:55:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/07/03 02:55:07 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting tuned → {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "→ Accuracy: 0.980, Precision: 0.934, Recall: 0.851, F1: 0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/03 02:55:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/07/03 02:55:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN tuned → {'n_neighbors': 3}\n",
      "→ Accuracy: 0.971, Precision: 0.873, Recall: 0.821, F1: 0.846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/03 02:55:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/07/03 02:55:19 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM tuned → {'C': 10, 'kernel': 'rbf'}\n",
      "→ Accuracy: 0.977, Precision: 0.918, Recall: 0.836, F1: 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/03 02:55:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'BankLoanBestModel' already exists. Creating a new version of this model...\n",
      "2025/07/03 02:55:22 WARNING mlflow.tracking._model_registry.fluent: Run with id 48d11f152f7442119e14ad6606b716cb has no artifacts at artifact path 'model', registering model based on models:/m-6a284a10091843c6a42e399ab222cfd2 instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 Registering best model: RandomForest (F1=0.903)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '5' of model 'BankLoanBestModel'.\n",
      "C:\\Users\\Minfy.DESKTOP-ISK45CC.000\\AppData\\Local\\Temp\\ipykernel_12748\\2780369429.py:136: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Registered: BankLoanBestModel, version 5\n",
      "🚀 BankLoanBestModel v5 → Production\n",
      "📄 Logged HTML: evidently_train_vs_test_2025-07-03_02-55-24.html\n",
      "🗄️  Logged JSON: evidently_train_vs_test_2025-07-03_02-55-24.json\n",
      "🔢 drifted_columns_count = 0.0\n",
      "🔢 drifted_columns_share = 0.0\n",
      "🔢 dataset_row_count = 1500.0\n",
      "🔢 dataset_column_count = 11.0\n",
      "🔢 drift_Age = 0.028061626698313084\n",
      "🔢 drift_CCAvg = 0.03250447331201192\n",
      "🔢 drift_Experience = 0.026506967833842664\n",
      "🔢 drift_Income = 0.029321736822988533\n",
      "🔢 drift_Mortgage = 0.02517476499730154\n",
      "🔢 drift_CD Account = 0.00032384174356389915\n",
      "🔢 drift_CreditCard = 0.01668874408751289\n",
      "🔢 drift_Education = 0.012499112211892531\n",
      "🔢 drift_Family = 0.018132241949840956\n",
      "🔢 drift_Online = 0.0005154147823947248\n",
      "🔢 drift_Securities Account = 0.003982768135332864\n",
      "✅ All requested drift & dataset metrics logged to MLflow.\n",
      "📄 Logged HTML: evidently_train_vs_new_batch_2025-07-03_02-55-26.html\n",
      "🗄️  Logged JSON: evidently_train_vs_new_batch_2025-07-03_02-55-26.json\n",
      "🔢 drifted_columns_count = 10.0\n",
      "🔢 drifted_columns_share = 0.9090909090909091\n",
      "🔢 dataset_row_count = 15.0\n",
      "🔢 dataset_column_count = 11.0\n",
      "🔢 drift_Age = 0.6784517260788467\n",
      "🔢 drift_CCAvg = 0.2018694528101691\n",
      "🔢 drift_Experience = 0.6592922581420442\n",
      "🔢 drift_Income = 0.22937836837607442\n",
      "🔢 drift_CD Account = 0.14356849266624733\n",
      "🔢 drift_CreditCard = 0.21021766954612256\n",
      "🔢 drift_Education = 0.12319208872316273\n",
      "🔢 drift_Family = 0.16287618565307088\n",
      "🔢 drift_Mortgage = 0.40339915956512784\n",
      "🔢 drift_Online = 0.09412213922767908\n",
      "🔢 drift_Securities Account = 0.19281117723521934\n",
      "✅ All requested drift & dataset metrics logged to MLflow.\n",
      "📄 Logged HTML: evidently_test_vs_new_batch_2025-07-03_02-55-27.html\n",
      "🗄️  Logged JSON: evidently_test_vs_new_batch_2025-07-03_02-55-27.json\n",
      "🔢 drifted_columns_count = 10.0\n",
      "🔢 drifted_columns_share = 0.9090909090909091\n",
      "🔢 dataset_row_count = 15.0\n",
      "🔢 dataset_column_count = 11.0\n",
      "🔢 drift_Age = 0.706391439030911\n",
      "🔢 drift_CCAvg = 0.19097116227726912\n",
      "🔢 drift_Experience = 0.6840579730575301\n",
      "🔢 drift_Income = 0.24990218792297497\n",
      "🔢 drift_CD Account = 0.1432982600797981\n",
      "🔢 drift_CreditCard = 0.22610293852562893\n",
      "🔢 drift_Education = 0.1318583372899813\n",
      "🔢 drift_Family = 0.15836984465054582\n",
      "🔢 drift_Mortgage = 0.39824121018964054\n",
      "🔢 drift_Online = 0.09463520038696382\n",
      "🔢 drift_Securities Account = 0.19614023756878277\n",
      "✅ All requested drift & dataset metrics logged to MLflow.\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
